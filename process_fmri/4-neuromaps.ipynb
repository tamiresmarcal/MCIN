{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://files.osf.io/v1/resources/4mw3a/providers/osfstorage/60b684b53a6df1021bd4df2d ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (3 seconds, 0 min)\n",
      "Extracting data from /home/tamires/neuromaps-data/599046a594e0e45c04e90291c2348cbe/fsLR32k.tar.gz..... done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['midthickness', 'inflated', 'veryinflated', 'sphere', 'medial', 'sulc', 'vaavg'])\n",
      "(32492, 3) (64980, 3)\n",
      "Available annotations: 80\n",
      "Available volumetric annotations: 41\n",
      "[('abagen', 'genepc1', 'fsaverage', '10k')]\n",
      "['ASL', 'MEG', 'MRI', 'PET', 'fMRI', 'functional', 'genetics', 'meta-analysis', 'metabolism', 'receptors', 'resteyesopen', 'structural']\n",
      "[('margulies2016', 'fcgradient01', 'fsLR', '32k'), ('margulies2016', 'fcgradient02', 'fsLR', '32k'), ('margulies2016', 'fcgradient03', 'fsLR', '32k'), ('margulies2016', 'fcgradient04', 'fsLR', '32k'), ('margulies2016', 'fcgradient05', 'fsLR', '32k'), ('margulies2016', 'fcgradient06', 'fsLR', '32k'), ('margulies2016', 'fcgradient07', 'fsLR', '32k'), ('margulies2016', 'fcgradient08', 'fsLR', '32k'), ('margulies2016', 'fcgradient09', 'fsLR', '32k'), ('margulies2016', 'fcgradient10', 'fsLR', '32k'), ('mueller2013', 'intersubjvar', 'fsLR', '164k'), ('neurosynth', 'cogpc1', 'MNI152', '2mm')]\n",
      "Downloading data from https://files.osf.io/v1/resources/4mw3a/providers/osfstorage/60c2290118f70b01fca797eb ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (1 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://files.osf.io/v1/resources/4mw3a/providers/osfstorage/60c228f5f3ce9401fa24e521 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ...done. (3 seconds, 0 min)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/tamires/neuromaps-data/annotations/abagen/genepc1/fsaverage/source-abagen_desc-genepc1_space-fsaverage_den-10k_hemi-L_feature.func.gii', '/home/tamires/neuromaps-data/annotations/abagen/genepc1/fsaverage/source-abagen_desc-genepc1_space-fsaverage_den-10k_hemi-R_feature.func.gii']\n",
      "['/home/tamires/neuromaps-data/annotations/abagen/genepc1/fsaverage/source-abagen_desc-genepc1_space-fsaverage_den-10k_hemi-L_feature.func.gii', '/home/tamires/neuromaps-data/annotations/abagen/genepc1/fsaverage/source-abagen_desc-genepc1_space-fsaverage_den-10k_hemi-R_feature.func.gii']\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Fetching atlases and annotations\n",
    "================================\n",
    "\n",
    "This example demonstrates how to use :mod:`neuromaps.datasets` to fetch\n",
    "atlases and annotations.\n",
    "\"\"\"\n",
    "\n",
    "###############################################################################\n",
    "# Much of the functionality of the ``neuromaps`` toolbox relies on the\n",
    "# atlases and atlas files provided with it. In many cases these atlases are\n",
    "# fetched \"behind-the-scenes\" when you call functions that depend on them, but\n",
    "# they can be accessed directly.\n",
    "#\n",
    "# There is a general purpose :func:`neuromaps.datasets.fetch_atlas`\n",
    "# function that can fetch any of the atlases provided with ``neuromaps``:\n",
    "\n",
    "from neuromaps import datasets\n",
    "\n",
    "fslr = datasets.fetch_atlas(atlas='fslr', density='32k')\n",
    "print(fslr.keys())\n",
    "\n",
    "###############################################################################\n",
    "# The values corresponding to the keys of the atlas dictionary are length-2\n",
    "# lists containing filepaths to the downloaded data. All surface atlas files\n",
    "# are provide in gifti format (whereas MNI files are in gzipped nifti format).\n",
    "#\n",
    "# You can load them directly with ``nibabel`` to confirm their validity:\n",
    "\n",
    "import nibabel as nib\n",
    "lsphere, rsphere = fslr['sphere']\n",
    "lvert, ltri = nib.load(lsphere).agg_data()\n",
    "print(lvert.shape, ltri.shape)\n",
    "\n",
    "###############################################################################\n",
    "# The other datasets that are provided with ``neuromaps`` are annotations\n",
    "# (i.e., brain maps!). While we are slowly making more and more of these openly\n",
    "# available, for now only a subset are accessible to the general public; these\n",
    "# are returned by default via :func:`datasets.available_annotations`.\n",
    "\n",
    "annotations = datasets.available_annotations()\n",
    "print(f'Available annotations: {len(annotations)}')\n",
    "\n",
    "###############################################################################\n",
    "# The :func:`~.available_annotations` function accepts a number of keyword\n",
    "# arguments that you can use to query specific datasets. For example, providing\n",
    "# the `format='volume`' argument will return only those annotations that\n",
    "# are, by default, a volumetric image:\n",
    "\n",
    "volume_annotations = datasets.available_annotations(format='volume')\n",
    "print(f'Available volumetric annotations: {len(volume_annotations)}')\n",
    "\n",
    "###############################################################################\n",
    "# There are a number of keyword arguments we can specify to reduce the scope of\n",
    "# the annotations returned. Here, `source` specifies where the annotation came\n",
    "# from (i.e., a dataset from a manuscript or a data repository or toolbox),\n",
    "# `desc` refers to a brief description of the annotation, `space` clarifies\n",
    "# which space the annotation is in, and `den` (specific to surface annotations)\n",
    "# clarifies the density of the surface on which the annotation is defined:\n",
    "\n",
    "annot = datasets.available_annotations(source='abagen', desc='genepc1',\n",
    "                                       space='fsaverage', den='10k')\n",
    "print(annot)\n",
    "\n",
    "###############################################################################\n",
    "# Annotations also have tags to help sort them into categories. You can see\n",
    "# what tags can be used to query annotations with the :func:`~.available_tags`\n",
    "# functions:\n",
    "\n",
    "tags = datasets.available_tags()\n",
    "print(tags)\n",
    "\n",
    "###############################################################################\n",
    "# Tags can be used as a keyword argument with :func:`~.available_annotations`.\n",
    "# You can supply either a single tag or a list of tags. Note that supplying a\n",
    "# list will only return those annotations that match ALL supplied tags:\n",
    "\n",
    "fmri_annotations = datasets.available_annotations(tags='fMRI')\n",
    "print(fmri_annotations)\n",
    "\n",
    "###############################################################################\n",
    "# Once we have an annotation that we want we can use the\n",
    "# :func:`neuromaps.datasets.fetch_annotation` to actually download the\n",
    "# files. This has a very similar signature to the\n",
    "# :func:`~.available_annotations` function, accepting almost all the same\n",
    "# keyword arguments to specify which annotations are desired.\n",
    "#\n",
    "# Here, we'll grab the first principal component of gene expression across the\n",
    "# brain (from the Allen Human Brain Atlas):\n",
    "\n",
    "abagen = datasets.fetch_annotation(source='abagen', desc='genepc1')\n",
    "print(abagen)\n",
    "\n",
    "###############################################################################\n",
    "# Notice that the returned annotation ``abagen`` is a dictionary. We can subset\n",
    "# the dictionary with the appropriate key or, if we know that our query is\n",
    "# going to return only one annotation, also provide the `return_single=True`\n",
    "# argument to the fetch call:\n",
    "\n",
    "abagen = datasets.fetch_annotation(source='abagen', desc='genepc1',\n",
    "                                   return_single=True)\n",
    "print(abagen)\n",
    "\n",
    "###############################################################################\n",
    "# And that's it! This example provided a quick overview on how to fetch the\n",
    "# various atlases and datasets provided with ``neuromaps``. For more\n",
    "# information please refer to the :ref:`API reference <ref_datasets>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neurosynth:  /home/tamires/neuromaps-data/annotations/neurosynth/cogpc1/MNI152/source-neurosynth_desc-cogpc1_space-MNI152_res-2mm_feature.nii.gz\n",
      "Gene PC1:  ['/home/tamires/neuromaps-data/annotations/abagen/genepc1/fsaverage/source-abagen_desc-genepc1_space-fsaverage_den-10k_hemi-L_feature.func.gii', '/home/tamires/neuromaps-data/annotations/abagen/genepc1/fsaverage/source-abagen_desc-genepc1_space-fsaverage_den-10k_hemi-R_feature.func.gii']\n",
      "(<nibabel.gifti.gifti.GiftiImage object at 0x2ad003d2cb60>, <nibabel.gifti.gifti.GiftiImage object at 0x2ad003d2da90>) (<nibabel.gifti.gifti.GiftiImage object at 0x2ad08891fc80>, <nibabel.gifti.gifti.GiftiImage object at 0x2ad08891e540>)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argument should be a str or an os.PathLike object where __fspath__ returns a str, not 'GiftiImage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 59\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m###############################################################################\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Once the images are resampled we can easily correlate them:\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mneuromaps\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stats\n\u001b[0;32m---> 59\u001b[0m corr \u001b[38;5;241m=\u001b[39m stats\u001b[38;5;241m.\u001b[39mcompare_images(nsynth, genepc)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCorrelation: r = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcorr\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.02f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m###############################################################################\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# What if we want to assess the statistical significance of this correlation?\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# In this case, we can use a null model from the :mod:`neuromaps.nulls` module.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# (Note that we need to pass the loaded data from the provided map to the null\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# function so we use the :func:`neuromaps.images.load_data` utility.)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/neuromaps/stats.py:71\u001b[0m, in \u001b[0;36mcompare_images\u001b[0;34m(src, trg, metric, ignore_zero, nulls, nan_policy, return_nulls)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_nulls \u001b[38;5;129;01mand\u001b[39;00m nulls \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`return_nulls` cannot be True when `nulls` is None.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 71\u001b[0m srcdata, trgdata \u001b[38;5;241m=\u001b[39m load_data(src), load_data(trg)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# drop NaNs (if nan_policy==`omit`) and zeros (if ignore_zero=True)\u001b[39;00m\n\u001b[1;32m     74\u001b[0m zeromask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(srcdata), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/neuromaps/images.py:227\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    225\u001b[0m             out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(data, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 227\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msqueeze(out)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/neuromaps/images.py:202\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    200\u001b[0m data_gii \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[0;32m--> 202\u001b[0m     data_hemi \u001b[38;5;241m=\u001b[39m load_gifti(img)\u001b[38;5;241m.\u001b[39magg_data()\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# More than one data arrays without NIFTI_INTENT_TIMESERIES\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_hemi, \u001b[38;5;28mtuple\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/neuromaps/images.py:170\u001b[0m, in \u001b[0;36mload_gifti\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# it's not a pre-loaded GiftiImage so error out\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(err, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[1;32m    166\u001b[0m           \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[1;32m    167\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mos.PathLike\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot GiftiImage\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err)\n\u001b[1;32m    168\u001b[0m               )\n\u001b[1;32m    169\u001b[0m           ):\n\u001b[0;32m--> 170\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/neuromaps/images.py:158\u001b[0m, in \u001b[0;36mload_gifti\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03mLoad gifti file `img`.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;124;03m    Loaded GIFTI images\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     img \u001b[38;5;241m=\u001b[39m nib\u001b[38;5;241m.\u001b[39mload(img)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ImageFileError, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# it's gzipped, so read the gzip and pipe it in\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, ImageFileError) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.gii.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/nibabel/loadsave.py:96\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(filename: FileSpec, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FileBasedImage:\n\u001b[1;32m     82\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Load file given filename, guessing at file type\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m       Image of guessed type\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m     filename \u001b[38;5;241m=\u001b[39m _stringify_path(filename)\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# Check file exists and is not empty\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/nibabel/filename_parser.py:41\u001b[0m, in \u001b[0;36m_stringify_path\u001b[0;34m(filepath_or_buffer)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_stringify_path\u001b[39m(filepath_or_buffer: FileSpec) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m     26\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Attempt to convert a path-like object to a string.\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m    https://github.com/pandas-dev/pandas/blob/325dd68/pandas/io/common.py#L131-L160\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pathlib\u001b[38;5;241m.\u001b[39mPath(filepath_or_buffer)\u001b[38;5;241m.\u001b[39mexpanduser()\u001b[38;5;241m.\u001b[39mas_posix()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/pathlib.py:1162\u001b[0m, in \u001b[0;36mPath.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1159\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupport for supplying keyword arguments to pathlib.PurePath \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1160\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis deprecated and scheduled for removal in Python \u001b[39m\u001b[38;5;132;01m{remove}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1161\u001b[0m     warnings\u001b[38;5;241m.\u001b[39m_deprecated(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpathlib.PurePath(**kwargs)\u001b[39m\u001b[38;5;124m\"\u001b[39m, msg, remove\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m14\u001b[39m))\n\u001b[0;32m-> 1162\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/pathlib.py:373\u001b[0m, in \u001b[0;36mPurePath.__init__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    371\u001b[0m             path \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m    372\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 373\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    374\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margument should be a str or an os.PathLike \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    375\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject where __fspath__ returns a str, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    376\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(path)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    377\u001b[0m         paths\u001b[38;5;241m.\u001b[39mappend(path)\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raw_paths \u001b[38;5;241m=\u001b[39m paths\n",
      "\u001b[0;31mTypeError\u001b[0m: argument should be a str or an os.PathLike object where __fspath__ returns a str, not 'GiftiImage'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Using spatial null models\n",
    "=========================\n",
    "\n",
    "This example demonstrates how to use spatial null models in\n",
    ":mod:`neuromaps.nulls` to test the correlation between two brain\n",
    "annotations.\n",
    "\"\"\"\n",
    "\n",
    "###############################################################################\n",
    "# The brain—and most features derived from it—is spatially autocorrelated, and\n",
    "# therefore when making comparisons between brain features we need to account\n",
    "# for this spatial autocorrelation.\n",
    "#\n",
    "# Enter: spatial null models.\n",
    "#\n",
    "# Spatial null models need to be used whenever you're comparing brain maps. In\n",
    "# order to demonstrate how use them in ``neuromaps`` we need two\n",
    "# annotations to compare. We'll use the first principal component of cognitive\n",
    "# terms from NeuroSynth (Yarkoni et al., 2011, Nat Methods) and the first\n",
    "# principal component of gene expression across the brain (from the Allen Human\n",
    "# Brain Atlas).\n",
    "#\n",
    "# Note that we pass `return_single=True` to\n",
    "# :func:`neuromaps.datasets.fetch_annotation` so that the returned data are\n",
    "# a list of filepaths rather than the default dictionary format. (This only\n",
    "# works since we know that there is only one annotation matching our query; a\n",
    "# dictionary will always be returned if multiple annotations match our query.)\n",
    "\n",
    "from neuromaps import datasets\n",
    "nsynth = datasets.fetch_annotation(source='neurosynth', return_single=True)\n",
    "genepc = datasets.fetch_annotation(desc='genepc1', return_single=True)\n",
    "print('Neurosynth: ', nsynth)\n",
    "print('Gene PC1: ', genepc)\n",
    "\n",
    "###############################################################################\n",
    "# These annotations are in different spaces so we first need to resample them\n",
    "# to the same space. Here, we'll choose to resample them to the 'fsaverage'\n",
    "# surface with a '10k' resolution (approx 10k vertices per hemisphere). Note\n",
    "# that the `genepc1` is already in this space so no resampling will be\n",
    "# performed for those data. (We could alternatively specify 'transform_to_trg'\n",
    "# for the `resampling` parameter and achieve the same outcome.)\n",
    "#\n",
    "# The data returned will always be pre-loaded nibabel image instances:\n",
    "\n",
    "from neuromaps import resampling\n",
    "nsynth, genepc = resampling.resample_images(src=nsynth, trg=genepc,\n",
    "                                            src_space='MNI152',\n",
    "                                            trg_space='fsaverage',\n",
    "                                            resampling='transform_to_alt',\n",
    "                                            alt_spec=('fsaverage', '10k'))\n",
    "print(nsynth, genepc)\n",
    "\n",
    "###############################################################################\n",
    "# Once the images are resampled we can easily correlate them:\n",
    "\n",
    "from neuromaps import stats\n",
    "corr = stats.compare_images(nsynth, genepc)\n",
    "print(f'Correlation: r = {corr:.02f}')\n",
    "\n",
    "###############################################################################\n",
    "# What if we want to assess the statistical significance of this correlation?\n",
    "# In this case, we can use a null model from the :mod:`neuromaps.nulls` module.\n",
    "#\n",
    "# Here, we'll employ the null model proposed in Alexander-Bloch et al., 2018,\n",
    "# *NeuroImage*. We provide one of the maps we're comparing, the space + density\n",
    "# of the map, and the number of permutations we want to generate. The returned\n",
    "# array will have two dimensions, where each row corresponds to a vertex and\n",
    "# each column to a unique permutation.\n",
    "#\n",
    "# (Note that we need to pass the loaded data from the provided map to the null\n",
    "# function so we use the :func:`neuromaps.images.load_data` utility.)\n",
    "\n",
    "from neuromaps import images, nulls\n",
    "nsynth_data = images.load_data(nsynth)\n",
    "rotated = nulls.alexander_bloch(nsynth_data, atlas='fsaverage', density='10k',\n",
    "                                n_perm=100, seed=1234)\n",
    "print(rotated.shape)\n",
    "\n",
    "###############################################################################\n",
    "# We can supply the generated null array to the\n",
    "# :func:`neuromaps.stats.compare_images` function and it will be used to\n",
    "# generate a non-parameteric p-value. The function assumes that the array\n",
    "# provided to the `nulls` parameter corresponds to the *first* dataset passed\n",
    "# to the function (i.e., `nsynth`).\n",
    "#\n",
    "# Note that the correlation remains identical to that above but the p-value is\n",
    "# now returned as well:\n",
    "\n",
    "corr, pval = stats.compare_images(nsynth, genepc, nulls=rotated)\n",
    "print(f'Correlation: r = {corr:.02f}, p = {pval:.04f}')\n",
    "\n",
    "###############################################################################\n",
    "# There are a number of different null functions that can be used to generate\n",
    "# null maps; they have (nearly) identical function signatures, so refer to the\n",
    "# :ref:`API reference <ref_nulls>` for more information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "singularity-neuroimaging",
   "language": "python",
   "name": "singularity-neuroimaging"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
