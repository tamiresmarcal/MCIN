{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c84e3e75-1bfd-4433-a515-dce9867ce1df",
   "metadata": {},
   "source": [
    "### Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d451eca3-2726-4886-84e3-db115026f258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Env\n",
    "import nibabel as nib\n",
    "from nilearn import datasets, input_data, plotting, connectome, image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import pearsonr, zscore\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import time\n",
    "import gc\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Functions\n",
    "def load_image(sub, movie):\n",
    "    path = os.path.join(f'/home/tamires/projects/rpp-aevans-ab/tamires/data/fmri_datasets/ds002837/derivatives/sub-{sub}/func', \n",
    "                        f'sub-{sub}_task-{movie}_bold_blur_no_censor_ica.nii.gz')\n",
    "    return nib.load(path, mmap=True)\n",
    "\n",
    "\n",
    "def save_correlation_data(networks_data, sub, movie): \n",
    "    # format dataframe\n",
    "    df = pd.DataFrame(networks_data, columns=['network', 'start', 'end', \n",
    "                                              'net_mean', 'net_median','net_std','net_mean_abs','net_median_abs','net_std_abs',\n",
    "                                              'fc_mean_abs','fc_median_abs','fc_std_abs'])\n",
    "    df['sub'] = sub\n",
    "    df['movie'] = movie\n",
    "    \n",
    "    # file name\n",
    "    base_filename = f'/home/tamires/projects/rpp-aevans-ab/tamires/data/fmri_derived/networks_data/sub-{sub}_task-{movie}_networks'\n",
    "    version = 1\n",
    "    filename = f\"{base_filename}_v{version}.parquet\"\n",
    "    \n",
    "    # check if there is a previous version\n",
    "    while os.path.exists(filename):\n",
    "        version += 1\n",
    "        filename = f\"{base_filename}_v{version}.parquet\"\n",
    "        \n",
    "    df.to_parquet(filename)\n",
    "\n",
    "\n",
    "def brain_networks_extraction(df_networks, network_name, fmri_img, radius = 6):\n",
    "    # Coordinates\n",
    "    peak_coords = df_networks[df_networks.name == network_name][['x', 'y', 'z']].values\n",
    "    # Create 6mm spheres around these coordinates\n",
    "    spheres_masker = input_data.NiftiSpheresMasker(seeds=peak_coords, radius=radius, standardize=True)\n",
    "    # Extract time series data for each sphere\n",
    "    time_series = spheres_masker.fit_transform(fmri_img) \n",
    "    return time_series\n",
    "\n",
    "\n",
    "def network_statistic(time_series):\n",
    "    net_stats = [np.mean(time_series), \n",
    "                 np.median(time_series), \n",
    "                 np.std(time_series),\n",
    "                 np.mean(abs(time_series)), \n",
    "                 np.median(abs(time_series)), \n",
    "                 np.std(abs(time_series))]\n",
    "    return net_stats\n",
    "    \n",
    "\n",
    "def functional_conectivity_statistic(time_series):\n",
    "    # Compute the functional connectome using ConnectivityMeasure\n",
    "    correlation_measure = connectome.ConnectivityMeasure(kind='correlation')\n",
    "    correlation_matrix = correlation_measure.fit_transform([time_series])[0]\n",
    "    fc_stats = [np.mean(abs(correlation_matrix)), \n",
    "                np.median(abs(correlation_matrix)), \n",
    "                np.std(abs(correlation_matrix))]\n",
    "    return fc_stats\n",
    "\n",
    "\n",
    "def process_time_intervals(img_original, network_list, start, end, step, radius=2):\n",
    "    \"\"\" Extract data of interval using brain_networks_extraction, network_statistic and functional_conectivity_statistic \"\"\"\n",
    "    \n",
    "    networks_data = []\n",
    "    for t in range(start, end, step):\n",
    "        img = img_original.dataobj[:,:,:,t:t+step]\n",
    "        img = nib.Nifti1Image(img, img_original.affine, img_original.header)\n",
    "        \n",
    "        for network_name in network_list:\n",
    "            time_series = brain_networks_extraction(df_networks, network_name=network_name, fmri_img=img, radius=radius)\n",
    "            net_stats = network_statistic(time_series)\n",
    "            fc_stats = functional_conectivity_statistic(time_series)\n",
    "            networks_data.append([network_name, t, t+step] + net_stats + fc_stats) \n",
    "            #print(f\"{network_name} | clip start: {t} | clip end: {t+step}\")\n",
    "    \n",
    "    return networks_data\n",
    "\n",
    "\n",
    "def process_participant(sub, movie, network_list, end, duration, step):\n",
    "    print(f\"Initializing processing participant {sub} | {movie}\")\n",
    "    \n",
    "    # Load: 153 ms\n",
    "    img_original = load_image(sub, movie)\n",
    "    \n",
    "    # Process: 2s per interval per network\n",
    "    start = end - duration\n",
    "    networks_data = process_time_intervals(img_original, network_list, start=start, end=end, step=step)\n",
    "    \n",
    "    # Save: 600ms\n",
    "    save_correlation_data(networks_data, sub, movie)\n",
    "    print(f\"File saved participant {sub} | {movie}\")\n",
    "\n",
    "\n",
    "# Data\n",
    "df_networks = pd.read_csv(\"/home/tamires/projects/rpp-aevans-ab/tamires/data/fmri_derived/mni_space_of_networks.csv\")\n",
    "participants = pd.read_csv(\"/home/tamires/projects/rpp-aevans-ab/tamires/data/fmri_datasets/ds002837/participants.tsv\", sep='\\t')\n",
    "participants['sub'] = range(1,87)\n",
    "participants = participants[participants['sub'] != 49] # ta corrompido\n",
    "participants['end'] = [load_image(sub=row['sub'], movie=row['task']).shape[3] for index, row in participants.iterrows()]\n",
    "\n",
    "\n",
    "# Parameters\n",
    "participants_test = participants.iloc[20:22]\n",
    "network_list = df_networks.name.unique()[:2]\n",
    "duration = 20 #30 * 60\n",
    "step = 10\n",
    "\n",
    "# Set the number of jobs (parallel workers)\n",
    "n_jobs = 5  # Adjust this number based on your system's capacity\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"  # Ensure thread limiting if needed\n",
    "results = Parallel(n_jobs=n_jobs)(\n",
    "    delayed(process_participant)(sub, movie, network_list, end, duration, step)\n",
    "    for sub, movie, end in participants_test[['sub', 'task','end']].values\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e680280-248d-4421-be80-b8972090919b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>network</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>net_mean</th>\n",
       "      <th>net_median</th>\n",
       "      <th>net_std</th>\n",
       "      <th>net_mean_abs</th>\n",
       "      <th>net_median_abs</th>\n",
       "      <th>net_std_abs</th>\n",
       "      <th>fc_mean_abs</th>\n",
       "      <th>fc_median_abs</th>\n",
       "      <th>fc_std_abs</th>\n",
       "      <th>sub</th>\n",
       "      <th>movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autobiographical memory</td>\n",
       "      <td>6784</td>\n",
       "      <td>6794</td>\n",
       "      <td>-2.073205e-09</td>\n",
       "      <td>0.003265</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.823056</td>\n",
       "      <td>0.727116</td>\n",
       "      <td>0.567960</td>\n",
       "      <td>0.178130</td>\n",
       "      <td>0.131984</td>\n",
       "      <td>0.196055</td>\n",
       "      <td>21</td>\n",
       "      <td>citizenfour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cognitive attention control</td>\n",
       "      <td>6784</td>\n",
       "      <td>6794</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.015591</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.834939</td>\n",
       "      <td>0.770243</td>\n",
       "      <td>0.550342</td>\n",
       "      <td>0.102235</td>\n",
       "      <td>0.047209</td>\n",
       "      <td>0.215255</td>\n",
       "      <td>21</td>\n",
       "      <td>citizenfour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Autobiographical memory</td>\n",
       "      <td>6794</td>\n",
       "      <td>6804</td>\n",
       "      <td>-2.073205e-08</td>\n",
       "      <td>0.039848</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.841316</td>\n",
       "      <td>0.754791</td>\n",
       "      <td>0.540544</td>\n",
       "      <td>0.161658</td>\n",
       "      <td>0.118134</td>\n",
       "      <td>0.196267</td>\n",
       "      <td>21</td>\n",
       "      <td>citizenfour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cognitive attention control</td>\n",
       "      <td>6794</td>\n",
       "      <td>6804</td>\n",
       "      <td>1.505802e-08</td>\n",
       "      <td>-0.027401</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.823006</td>\n",
       "      <td>0.722463</td>\n",
       "      <td>0.568032</td>\n",
       "      <td>0.140688</td>\n",
       "      <td>0.091142</td>\n",
       "      <td>0.210878</td>\n",
       "      <td>21</td>\n",
       "      <td>citizenfour</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       network  start   end      net_mean  net_median  \\\n",
       "0      Autobiographical memory   6784  6794 -2.073205e-09    0.003265   \n",
       "1  Cognitive attention control   6784  6794  0.000000e+00   -0.015591   \n",
       "2      Autobiographical memory   6794  6804 -2.073205e-08    0.039848   \n",
       "3  Cognitive attention control   6794  6804  1.505802e-08   -0.027401   \n",
       "\n",
       "   net_std  net_mean_abs  net_median_abs  net_std_abs  fc_mean_abs  \\\n",
       "0      1.0      0.823056        0.727116     0.567960     0.178130   \n",
       "1      1.0      0.834939        0.770243     0.550342     0.102235   \n",
       "2      1.0      0.841316        0.754791     0.540544     0.161658   \n",
       "3      1.0      0.823006        0.722463     0.568032     0.140688   \n",
       "\n",
       "   fc_median_abs  fc_std_abs  sub        movie  \n",
       "0       0.131984    0.196055   21  citizenfour  \n",
       "1       0.047209    0.215255   21  citizenfour  \n",
       "2       0.118134    0.196267   21  citizenfour  \n",
       "3       0.091142    0.210878   21  citizenfour  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet('/home/tamires/projects/rpp-aevans-ab/tamires/data/fmri_derived/networks_data/sub-21_task-citizenfour_networks_v2.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee8da41-b9a7-4b78-8af4-f0c24927384e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
